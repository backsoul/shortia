import { FFmpeg } from "@ffmpeg/ffmpeg";
import { fetchFile, toBlobURL } from "@ffmpeg/util";

let ffmpegInstance: FFmpeg | null = null;
let isLoading = false;

export async function getFFmpeg(): Promise<FFmpeg> {
  if (ffmpegInstance) {
    console.log("‚úÖ Reutilizando instancia de FFmpeg existente");
    return ffmpegInstance;
  }

  if (isLoading) {
    console.log("‚è≥ FFmpeg ya se est√° cargando, esperando...");
    while (isLoading) {
      await new Promise((resolve) => setTimeout(resolve, 100));
    }
    return ffmpegInstance!;
  }

  isLoading = true;
  console.log("üì¶ Creando nueva instancia de FFmpeg...");
  ffmpegInstance = new FFmpeg();

  // Usar archivos locales servidos desde /static/ffmpeg/
  const baseURL = "/ffmpeg";

  ffmpegInstance.on("log", ({ message }) => {
    console.log("[FFmpeg Log]", message);
  });

  ffmpegInstance.on("progress", ({ progress, time }) => {
    console.log(
      `[FFmpeg Progress] ${Math.round(progress * 100)}% - Time: ${time}¬µs`
    );
  });

  try {
    console.log("üåê Cargando FFmpeg core desde archivos locales:", baseURL);

    const coreURL = await toBlobURL(
      `${baseURL}/ffmpeg-core.js`,
      "text/javascript"
    );
    console.log("‚úÖ ffmpeg-core.js cargado");

    const wasmURL = await toBlobURL(
      `${baseURL}/ffmpeg-core.wasm`,
      "application/wasm"
    );
    console.log("‚úÖ ffmpeg-core.wasm cargado");

    console.log("‚öôÔ∏è Inicializando FFmpeg...");
    await ffmpegInstance.load({
      coreURL,
      wasmURL,
    });
    console.log("‚úÖ FFmpeg loaded successfully");
  } catch (error) {
    console.error("‚ùå Failed to load FFmpeg:", error);
    isLoading = false;
    ffmpegInstance = null;
    throw error;
  }

  isLoading = false;
  return ffmpegInstance;
}

/**
 * Exporta clip usando MediaRecorder API + Canvas Rendering
 * Esta es la soluci√≥n Frontend-Only: los subt√≠tulos se renderizan en canvas
 * y se graban directamente como video, sin procesamiento backend.
 *
 * VENTAJAS:
 * - Una sola fuente de verdad para estilos
 * - Animaciones ilimitadas (CSS/Canvas)
 * - Sin duplicaci√≥n de c√≥digo
 * - WYSIWYG real
 *
 * @param canvasElement - Canvas con video + subt√≠tulos renderizados
 * @param videoElement - Elemento video para extraer audio
 * @param startTime - Tiempo de inicio
 * @param endTime - Tiempo de fin
 * @param onProgress - Callback de progreso (progress: 0-100, stage: string)
 * @param onCancel - Callback para detectar cancelaci√≥n (debe retornar true si fue cancelado)
 */
// Funci√≥n para detectar Safari
function isSafari(): boolean {
  return /^((?!chrome|android).)*safari/i.test(navigator.userAgent);
}

// Funci√≥n para verificar si captureStream est√° disponible
function isCaptureStreamSupported(): boolean {
  return "captureStream" in HTMLVideoElement.prototype;
}

export async function exportClipWithMediaRecorder(
  canvasElement: HTMLCanvasElement,
  videoElement: HTMLVideoElement,
  startTime: number,
  endTime: number,
  onProgress?: (progress: number, stage: string) => void,
  onCancel?: () => boolean
): Promise<Blob> {
  console.log("üé¨ Exportando con MediaRecorder API (Frontend-Only)");

  // Verificar compatibilidad con Safari
  if (isSafari() || !isCaptureStreamSupported()) {
    console.warn(
      "‚ö†Ô∏è Safari o captureStream no soportado, usando fallback con FFmpeg"
    );
    throw new Error("SAFARI_NOT_SUPPORTED");
  }

  return new Promise((resolve, reject) => {
    let recorder: MediaRecorder | null = null;
    let progressTimer: any = null;
    let recordingTimeout: any = null;
    let timeUpdateListener:
      | ((this: HTMLVideoElement, ev: Event) => any)
      | null = null;

    let restoreAudioState = () => {};
    let combinedStream: MediaStream | null = null;

    const cleanup = () => {
      if (progressTimer) clearInterval(progressTimer);
      if (recordingTimeout) clearTimeout(recordingTimeout);
      if (timeUpdateListener) {
        videoElement.removeEventListener("timeupdate", timeUpdateListener);
      }
      videoElement.onseeked = null;
      videoElement.pause();
      restoreAudioState();
      combinedStream
        ?.getTracks()
        .forEach((track: MediaStreamTrack) => track.stop());
    };

    try {
      if (onProgress) onProgress(5, "preparing");

      // Capturar stream del canvas con FPS optimizado para velocidad
      // 30 FPS es un buen balance entre calidad y velocidad de procesamiento
      const canvasStream = canvasElement.captureStream(30);
      console.log("‚úÖ Canvas stream capturado a 30fps");

      if (onProgress) onProgress(10, "preparing");

      // Capturar audio del video original
      let audioTracks: MediaStreamTrack[] = [];
      try {
        // @ts-ignore - captureStream est√° disponible en HTMLVideoElement cuando es soportado
        const videoStream = videoElement.captureStream();
        audioTracks = videoStream.getAudioTracks();
        console.log("‚úÖ Audio tracks extra√≠dos:", audioTracks.length);
      } catch (error) {
        console.warn("‚ö†Ô∏è No se pudo capturar audio del video:", error);
        // Continuar sin audio si hay problemas
      }

      // Combinar video del canvas + audio del video
      combinedStream = new MediaStream([
        ...canvasStream.getVideoTracks(),
        ...audioTracks,
      ]);

      const previousMuted = videoElement.muted;
      const previousVolume = videoElement.volume ?? 1;
      restoreAudioState = () => {
        videoElement.muted = previousMuted;
        videoElement.volume = previousVolume;
      };

      videoElement.muted = true;
      videoElement.volume = 0;

      const chunks: Blob[] = [];

      // Usar VP8 que es m√°s r√°pido de codificar que VP9
      let mimeType = "video/webm;codecs=vp8,opus";
      if (!MediaRecorder.isTypeSupported(mimeType)) {
        mimeType = "video/webm;codecs=vp9,opus";
      }
      if (!MediaRecorder.isTypeSupported(mimeType)) {
        mimeType = "video/webm";
      }
      console.log("üìπ Usando codec:", mimeType);

      recorder = new MediaRecorder(combinedStream!, {
        mimeType,
        videoBitsPerSecond: 5000000, // 5 Mbps - reducido para velocidad sin perder mucha calidad
      });

      recorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunks.push(event.data);
          console.log("üì¶ Chunk recibido:", event.data.size, "bytes");
        }
      };

      recorder.onstop = () => {
        cleanup();

        // Verificar cancelaci√≥n
        if (onCancel && onCancel()) {
          console.log("‚ùå Exportaci√≥n cancelada por usuario");
          reject(new Error("Exportaci√≥n cancelada"));
          return;
        }

        const blob = new Blob(chunks, { type: mimeType });
        console.log("‚úÖ Grabaci√≥n completada:", blob.size, "bytes");
        if (onProgress) onProgress(90, "finalizing");

        // Peque√±o delay para mostrar el estado de finalizaci√≥n
        setTimeout(() => {
          if (onProgress) onProgress(100, "complete");
          resolve(blob);
        }, 500);
      };

      recorder.onerror = (error) => {
        console.error("‚ùå Error en grabaci√≥n:", error);
        cleanup();
        reject(error);
      };

      if (onProgress) onProgress(15, "extracting");

      // Posicionar video en inicio del clip
      videoElement.currentTime = startTime;

      let isRecordingStarted = false; // Flag para evitar m√∫ltiples inicios

      // Listener para detener la grabaci√≥n cuando el video llegue al endTime
      timeUpdateListener = () => {
        if (
          videoElement.currentTime >= endTime &&
          recorder &&
          recorder.state !== "inactive"
        ) {
          console.log("‚èπÔ∏è Video lleg√≥ al endTime, deteniendo grabaci√≥n");
          if (onProgress) onProgress(85, "encoding");
          recorder.stop();
          videoElement.pause();
          if (timeUpdateListener) {
            videoElement.removeEventListener("timeupdate", timeUpdateListener);
          }
        }
      };

      videoElement.onseeked = () => {
        // Evitar m√∫ltiples inicios
        if (isRecordingStarted) {
          console.log("‚ö†Ô∏è Ignorando evento onseeked duplicado");
          return;
        }

        // Verificar cancelaci√≥n antes de iniciar
        if (onCancel && onCancel()) {
          console.log("‚ùå Exportaci√≥n cancelada antes de iniciar grabaci√≥n");
          restoreAudioState();
          videoElement.onseeked = null;
          videoElement.pause();
          combinedStream
            ?.getTracks()
            .forEach((track: MediaStreamTrack) => track.stop());
          reject(new Error("Exportaci√≥n cancelada"));
          return;
        }

        isRecordingStarted = true;
        console.log(
          "‚ñ∂Ô∏è Iniciando grabaci√≥n en",
          startTime,
          "s hasta",
          endTime,
          "s"
        );
        if (onProgress) onProgress(20, "rendering");

        // Chunks m√°s grandes = menos overhead = m√°s r√°pido
        // 500ms chunks en vez de 100ms
        recorder!.start(500);

        // Agregar listener para detener cuando llegue al endTime
        if (timeUpdateListener) {
          videoElement.addEventListener("timeupdate", timeUpdateListener);
        }

        videoElement.play();

        // Duraci√≥n del clip
        const duration = (endTime - startTime) * 1000; // ms
        console.log("‚è±Ô∏è Duraci√≥n del clip:", duration / 1000, "segundos");

        // Detener al final (fallback por si timeupdate falla)
        recordingTimeout = setTimeout(() => {
          if (recorder && recorder.state !== "inactive") {
            console.log("‚èπÔ∏è Deteniendo grabaci√≥n por timeout (fallback)");
            if (onProgress) onProgress(85, "encoding");
            recorder.stop();
            videoElement.pause();
            if (timeUpdateListener) {
              videoElement.removeEventListener(
                "timeupdate",
                timeUpdateListener
              );
            }
          }
        }, duration + 500); // Agregar 500ms extra como margen

        // Actualizar progreso durante grabaci√≥n
        if (onProgress) {
          let currentProgress = 20;
          const progressIncrement = 65 / (duration / 1000); // De 20% a 85% en la duraci√≥n

          progressTimer = setInterval(() => {
            // Verificar cancelaci√≥n
            if (onCancel && onCancel()) {
              console.log("‚ùå Cancelando exportaci√≥n...");
              if (recorder && recorder.state !== "inactive") {
                recorder.stop();
              }
              videoElement.pause();
              if (!recorder || recorder.state === "inactive") {
                restoreAudioState();
                combinedStream
                  ?.getTracks()
                  .forEach((track: MediaStreamTrack) => track.stop());
              }
              clearInterval(progressTimer);
              clearTimeout(recordingTimeout);
              return;
            }

            currentProgress += progressIncrement;
            if (currentProgress <= 85) {
              onProgress(
                Math.min(85, Math.round(currentProgress)),
                "rendering"
              );
            } else {
              clearInterval(progressTimer);
            }
          }, 1000); // Actualizar cada segundo
        }
      };
    } catch (error) {
      console.error("‚ùå Error configurando MediaRecorder:", error);
      cleanup();
      reject(error);
    }
  });
}

/**
 * Convierte un blob WebM a MP4 usando FFmpeg
 */
export async function convertWebMToMP4(
  webmBlob: Blob,
  onProgress?: (progress: number, stage: string) => void
): Promise<Blob> {
  console.log("üîÑ Convirtiendo WebM a MP4...");

  try {
    if (onProgress) onProgress(0, "loading-ffmpeg");
    if (onProgress) onProgress(40, "loading-ffmpeg");

    const ffmpeg = await getFFmpeg();

    if (onProgress) onProgress(60, "encoding");

    // Escribir archivo WebM temporal
    const webmData = await fetchFile(webmBlob);
    await ffmpeg.writeFile("input.webm", webmData);

    if (onProgress) onProgress(70, "encoding");

    console.log("‚öôÔ∏è Ejecutando conversi√≥n WebM -> MP4");

    // Convertir a MP4 con configuraci√≥n optimizada para VELOCIDAD
    await ffmpeg.exec([
      "-i",
      "input.webm",
      "-c:v",
      "libx264", // Codec H.264
      "-preset",
      "veryfast", // Preset m√°s r√°pido (ultrafast, superfast, veryfast, faster, fast, medium, slow, slower, veryslow)
      "-crf",
      "23", // CRF 23 = buena calidad, m√°s r√°pido que CRF 18
      "-c:a",
      "aac", // Codec de audio AAC
      "-b:a",
      "128k", // Bitrate de audio reducido (128k en vez de 192k)
      "-movflags",
      "+faststart", // Optimizar para streaming
      "-pix_fmt",
      "yuv420p", // Compatibilidad m√°xima
      "-threads",
      "0", // Usar todos los threads disponibles
      "output.mp4",
    ]);

    if (onProgress) onProgress(90, "finalizing");

    console.log("‚úÖ Conversi√≥n completada, leyendo archivo");
    const data = await ffmpeg.readFile("output.mp4");
    const mp4Blob = new Blob([data as any], { type: "video/mp4" });

    // Limpieza
    await ffmpeg.deleteFile("input.webm");
    await ffmpeg.deleteFile("output.mp4");

    if (onProgress) onProgress(100, "complete");

    console.log("‚úÖ MP4 generado:", mp4Blob.size, "bytes");
    return mp4Blob;
  } catch (error) {
    console.error("‚ùå Error convirtiendo a MP4:", error);
    throw error;
  }
}

/**
 * Convierte un video WebM a MP4 usando el backend (FFmpeg nativo)
 * Mucho m√°s r√°pido que la conversi√≥n en el navegador (10x m√°s r√°pido)
 *
 * @param webmBlob - Blob del video WebM
 * @param onProgress - Callback de progreso (progress: 0-100, stage: string)
 * @returns Blob del video MP4
 */
export async function convertWebMToMP4OnBackend(
  webmBlob: Blob,
  onProgress?: (progress: number, stage: string) => void
): Promise<Blob> {
  console.log("üöÄ Convirtiendo WebM a MP4 en backend (FFmpeg nativo)");

  try {
    if (onProgress) onProgress(10, "uploading");

    // Crear FormData con el archivo WebM
    const formData = new FormData();
    formData.append("video", webmBlob, "clip.webm");

    if (onProgress) onProgress(30, "converting");

    // Enviar al backend
    const response = await fetch(
      "http://localhost:8080/api/convert-webm-to-mp4",
      {
        method: "POST",
        body: formData,
      }
    );

    if (!response.ok) {
      const error = await response.json();
      throw new Error(error.error || "Conversion failed");
    }

    if (onProgress) onProgress(80, "downloading");

    // Recibir el MP4 convertido
    const mp4Blob = await response.blob();

    if (onProgress) onProgress(100, "complete");

    console.log("‚úÖ Conversi√≥n MP4 completa:", {
      originalSize: `${(webmBlob.size / 1024 / 1024).toFixed(2)} MB`,
      convertedSize: `${(mp4Blob.size / 1024 / 1024).toFixed(2)} MB`,
      type: mp4Blob.type,
    });

    return mp4Blob;
  } catch (error) {
    console.error("‚ùå Error convirtiendo WebM a MP4:", error);
    throw error;
  }
}

/**
 * Exporta clip con subt√≠tulos usando FFmpeg (fallback para Safari)
 * Usa una estrategia simplificada: extrae el clip original y superpone subt√≠tulos
 */
export async function exportClipWithFFmpeg(
  canvasElement: HTMLCanvasElement,
  videoElement: HTMLVideoElement,
  startTime: number,
  endTime: number,
  onProgress?: (progress: number, stage: string) => void,
  onCancel?: () => boolean
): Promise<Blob> {
  console.log("üé¨ Exportando con FFmpeg (Safari fallback)");

  try {
    if (onProgress) onProgress(10, "loading-ffmpeg");

    const ffmpeg = await getFFmpeg();
    const duration = endTime - startTime;

    // Obtener el video original
    const originalVideoUrl = videoElement.src;
    console.log("üì• Descargando video original...");

    if (onProgress) onProgress(20, "downloading");
    const videoData = await fetchFile(originalVideoUrl);
    await ffmpeg.writeFile("input.mp4", videoData);

    // Capturar una imagen del canvas con los subt√≠tulos actuales
    if (onProgress) onProgress(30, "capturing-subtitles");
    console.log("üì∏ Capturando subt√≠tulos del canvas...");

    // Posicionar video en el tiempo de inicio para capturar subt√≠tulos correctos
    videoElement.currentTime = startTime + duration / 2; // Usar el medio del clip
    await new Promise((resolve) => {
      videoElement.onseeked = () => {
        // Peque√±o delay para que el canvas se actualice
        setTimeout(resolve, 100);
      };
    });

    // Capturar el canvas como imagen de subt√≠tulos
    const subtitleBlob = await new Promise<Blob>((resolve) => {
      canvasElement.toBlob((blob) => {
        resolve(blob!);
      }, "image/png");
    });

    const subtitleData = new Uint8Array(await subtitleBlob.arrayBuffer());
    await ffmpeg.writeFile("subtitles.png", subtitleData);

    if (onProgress) onProgress(50, "processing");

    // Extraer el clip y superponer subt√≠tulos
    console.log("‚úÇÔ∏è Procesando clip con subt√≠tulos...");
    await ffmpeg.exec([
      "-ss",
      startTime.toString(),
      "-i",
      "input.mp4",
      "-i",
      "subtitles.png",
      "-t",
      duration.toString(),
      "-filter_complex",
      "[0:v]scale=1080:1920[bg]; [bg][1:v]overlay=(W-w)/2:(H-h)/2[v]",
      "-map",
      "[v]",
      "-map",
      "0:a?", // Audio opcional
      "-c:v",
      "libx264",
      "-preset",
      "medium",
      "-crf",
      "23",
      "-c:a",
      "aac",
      "-b:a",
      "128k",
      "-movflags",
      "+faststart",
      "output.mp4",
    ]);

    if (onProgress) onProgress(90, "finalizing");

    // Leer resultado
    const data = await ffmpeg.readFile("output.mp4");
    const resultBlob = new Blob([data as any], { type: "video/mp4" });

    // Limpiar archivos temporales
    try {
      await ffmpeg.deleteFile("input.mp4");
      await ffmpeg.deleteFile("subtitles.png");
      await ffmpeg.deleteFile("output.mp4");
    } catch (cleanupError) {
      console.warn("‚ö†Ô∏è Error limpiando archivos temporales:", cleanupError);
    }

    if (onProgress) onProgress(100, "complete");

    console.log("‚úÖ Exportaci√≥n FFmpeg completa:", {
      size: `${(resultBlob.size / 1024 / 1024).toFixed(2)} MB`,
      type: resultBlob.type,
      duration: `${duration}s`,
    });

    return resultBlob;
  } catch (error) {
    console.error("‚ùå Error en exportaci√≥n FFmpeg:", error);
    throw error;
  }
}

/**
 * Extrae solo el video clip sin subt√≠tulos (para procesamiento posterior)
 * √ötil cuando necesitas el clip crudo del backend
 */
export async function extractClipOnly(
  videoUrl: string,
  startTime: number,
  endTime: number,
  onProgress?: (progress: number, stage: string) => void
): Promise<Blob> {
  console.log("‚úÇÔ∏è Extrayendo clip sin subt√≠tulos");

  try {
    if (onProgress) onProgress(10, "loading-ffmpeg");

    const ffmpeg = await getFFmpeg();

    if (onProgress) onProgress(20, "downloading-video");

    const videoData = await fetchFile(videoUrl);
    await ffmpeg.writeFile("input.mp4", videoData);

    if (onProgress) onProgress(40, "processing");

    const duration = endTime - startTime;

    // Extraer clip con formato vertical optimizado
    await ffmpeg.exec([
      "-ss",
      startTime.toString(),
      "-i",
      "input.mp4",
      "-t",
      duration.toString(),
      "-vf",
      "scale=-1:1920,crop=min(iw\\,1080):1920", // Vertical 9:16
      "-c:v",
      "libx264",
      "-preset",
      "medium",
      "-crf",
      "18",
      "-c:a",
      "aac",
      "-b:a",
      "192k",
      "-movflags",
      "+faststart",
      "output.mp4",
    ]);

    if (onProgress) onProgress(80, "finalizing");

    const data = await ffmpeg.readFile("output.mp4");
    const blob = new Blob([data as any], { type: "video/mp4" });

    // Limpieza
    await ffmpeg.deleteFile("input.mp4");
    await ffmpeg.deleteFile("output.mp4");

    if (onProgress) onProgress(100, "complete");

    return blob;
  } catch (error) {
    console.error("‚ùå Error extrayendo clip:", error);
    throw error;
  }
}
